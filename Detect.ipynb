{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df89f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from model import Net\n",
    "import torch\n",
    "from imutils import face_utils\n",
    "import winsound as sd\n",
    "import pygame\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "IMG_SIZE = (34,26)\n",
    "PATH = \"./weights/trained.pth\"\n",
    "\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(PATH,map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "n_count = 0\n",
    "s_count = 0\n",
    "y_count = 0\n",
    "z_count = 0\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "\n",
    "def predict(pred):\n",
    "    pred = pred.transpose(1, 3).transpose(2, 3)\n",
    "\n",
    "    outputs = model(pred)\n",
    "\n",
    "    pred_tag = torch.round(torch.sigmoid(outputs))\n",
    "\n",
    "    return pred_tag\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1080)\n",
    "\n",
    "def beepsound():\n",
    "    sound1 = pygame.mixer.Sound(\"source.mp3\")\n",
    "    sound1.play()\n",
    "\n",
    "def beepsound2():\n",
    "    sound2 = pygame.mixer.Sound(\"source2.mp3\")\n",
    "    sound2.play()\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img_ori = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        cv2.imshow('l', eye_img_l)\n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32)\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32)\n",
    "\n",
    "\n",
    "        eye_input_l = torch.from_numpy(eye_input_l)\n",
    "        eye_input_r = torch.from_numpy(eye_input_r)\n",
    "\n",
    "\n",
    "        pred_l = predict(eye_input_l)\n",
    "        pred_r = predict(eye_input_r)\n",
    "\n",
    "        if pred_l.item() == 0.0 and pred_r.item() == 0.0:\n",
    "            n_count+=1\n",
    "                            \n",
    "        else:\n",
    "            n_count = 0\n",
    "           \n",
    "            \n",
    "        if n_count > 60:\n",
    "            cv2.putText(img,\"Wake up\", (120,160), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "            beepsound()\n",
    "            n_count = 0\n",
    "            s_count+=1\n",
    "            y_count=0\n",
    "        \n",
    "        else:\n",
    "            y_count+=1\n",
    "            \n",
    "        \n",
    "        if s_count > 2:\n",
    "            cv2.putText(img,\"YOU ARE IN DROWSINESS\", (120,160), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "                        \n",
    "            if y_count > 250:\n",
    "                s_count=0\n",
    "                y_count=0\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    # visualize left eye\n",
    "    if pred_l > 0.1:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,255,0), thickness=2)\n",
    "    \n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(0,0,255), thickness=2)\n",
    "\n",
    "    # visualize right eye    \n",
    "    if pred_r > 0.1:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,255,0), thickness=2)\n",
    "    \n",
    "    else:\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(0,0,255), thickness=2)\n",
    " \n",
    "    \n",
    "  #\n",
    "  # print(state_l)\n",
    "  # print(state_r)\n",
    "    cv2.imshow('result', img)\n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c12b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
